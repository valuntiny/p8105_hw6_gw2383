---
title: "p8105_hw6_gw2383"
author: "Guojing Wu"
date: "11/23/2018"
# output: html_document
output:
  github_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      message = F, 
                      warning = F)
library(tidyverse)
library(leaps)
library(patchwork)
theme_set(theme_bw())
```

## Problem 1

### Tidy data

```{r}
homi_df = 
  read.csv("./data/problem1/homicide-data.csv") %>% 
  janitor::clean_names() %>% 
  filter(victim_race != "Unknown") %>% # delete unknown races
  mutate(city_state = paste(city, state, sep = ", "), 
         solved = ifelse(disposition == "Closed by arrest", 1, 0), # a binary indicator
         victim_race = ifelse(victim_race == "White", "White", "Nonwhite"), 
         victim_race = factor(victim_race, levels = c("White", "Nonwhite")), # a white / non white indicator
         victim_age = as.numeric(victim_age)) %>% 
  filter(!(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"))) # filter cities
```

### a logistic regression

```{r}
# first fit it
fit_logistic =
  homi_df %>% 
  glm(solved ~ victim_age + victim_sex + victim_race, data = ., family = binomial())

# then compute the odds ratio
fit_logistic %>% 
  broom::tidy(conf.int = T) %>% 
  mutate(OR = exp(estimate), 
         conf.low = exp(conf.low), 
         conf.high = exp(conf.high)) %>% 
  select(term, OR, conf.low, conf.high, p.value) %>% 
  filter(term %in% c("(Intercept)", "victim_raceNonwhite")) %>% 
  knitr::kable()
```

### run `glm` for each of the cities

```{r}
nest_glm_res = 
  homi_df %>% 
  group_by(city_state) %>% 
  nest() %>% 
  mutate(models = map(data, ~glm(solved ~ victim_race + victim_age + victim_sex, data = .x, family = binomial())), 
         models_esti = map(models, broom::tidy), # tidying for estimate
         models_conf = map(models, broom::confint_tidy)) %>% # tyding for conf.int
  select(-data, -models) %>%
  unnest() %>% 
  filter(term %in% c("(Intercept)", "victim_raceNonwhite")) %>% 
  mutate(OR = exp(estimate), 
         conf.low = exp(conf.low), 
         conf.high = exp(conf.high)) %>% 
  select(city_state, term, OR, conf.low, conf.high, p.value)

nest_glm_res
```

Then create a plot that shows the estimated ORs and CIs for each city, and comment on the plot.

```{r, dpi = 300}
nest_glm_res %>% 
  filter(term == "victim_raceNonwhite") %>% 
  ggplot(aes(x = reorder(city_state, OR), y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  labs(x = "city", 
       y = "ORs and CIs for nonwhite victims comparing to white victims") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

According to this plot, we can see that across every cities, non white victims tend to have more unsolved homicides comparing to white victims (with `Boston, MA` has the least extra unsolved and `Tampa, FL` has the most extra unsolved).

## Problem 2

### Load and clean the data

```{r}
bw_df = 
  read.csv("./data/problem2/birthweight.csv") %>% 
  as.tibble() %>% 
  janitor::clean_names() %>% 
  select(bwt, everything())
```

* We first checked if there is `NA` in this dataset, and found out that there are `r sum(is.na(bw_df))` `NA`s.

* Second we check the collinearity:

```{r}
bw_df %>% 
  cor() %>% 
  knitr::kable()
```

We saw that the standard deviation for `pnumlbw` and `pnumsga` is 0, so we looked these two variables and found out that their sum is `r sum(bw_df$pnumlbw)` and `r sum(bw_df$pnumsga)`, which suggest that all the values in these two columns are 0s, so we need to remove these two columns.

We also saw that cor(`ppwt`, `delwt`), cor(`ppwt`, `ppbmi`) and cor(`frace`, `mrace`) are $\geq 0.8$. In these case, we remove the `ppwt` and `frace` columns since mother race is more related to child and BMI is more representative than body weight. Then we change some variable to factors:

```{r}
bw_df =
  bw_df %>% 
  select(-pnumlbw, -pnumsga, -ppwt, -frace) %>% 
  mutate(babysex = factor(babysex),
         malform = factor(malform),
         mrace = factor(mrace, levels = c(1, 2, 3, 4, 8)))
```

### Propose a regression model for birthweight

We first use stepwise procedures to see how many parameters shall be included in this model:

```{r, dpi = 300}
res_leap = 
  bw_df %>% 
  regsubsets(bwt ~ ., data = .) %>% 
  summary()

res_leap = tibble(
  number = c(2:10), 
  cp = res_leap$cp,
  adj = res_leap$adjr2,
  bic = res_leap$bic
)

cp_p = ggplot(res_leap, aes(x = number, y = cp)) +
  geom_point() +
  labs(x = "number of parameters", y = "Cp Statistic")

adj_p = ggplot(res_leap, aes(x = number, y = adj)) +
  geom_point() +
  labs(x = "number of parameters", y = "Adj R2")

bic_p = ggplot(res_leap, aes(x = number, y = bic)) +
  geom_point() +
  labs(x = "number of parameters", y = "BIC")

cp_p + adj_p + bic_p
```

From the plot we can see that a model contains 8 predictors seems the best, then we used AIC criterion stepwise method to find these 8 parameters:

```{r}
lm(bwt ~ ., data = bw_df) %>% 
  step(direction='backward')
```

So based on the result, the final paremeters we chose are: `intercept, blength, mrace, gaweeks, delwt, smoken, ppbmi, fincome`

```{r}
reg_optimal = lm(bwt ~ blength + mrace + gaweeks + delwt + smoken + ppbmi + fincome, data = bw_df)

bw_df %>% 
  modelr::add_predictions(reg_optimal) %>% 
  modelr::add_residuals(reg_optimal) %>% 
  ggplot(aes(x = pred, y = resid)) + geom_point()
```

### Compare your model to two others


