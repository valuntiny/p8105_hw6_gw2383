---
title: "p8105_hw6_gw2383"
author: "Guojing Wu"
date: "11/23/2018"
# output: html_document
output:
  github_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      message = F, 
                      warning = F, 
                      out.width = "90%")
library(tidyverse)
library(leaps)
library(patchwork)
theme_set(theme_bw())
```

## Problem 1

### Tidy data

```{r}
homi_df = 
  read.csv("./data/problem1/homicide-data.csv") %>% 
  janitor::clean_names() %>% 
  filter(victim_race != "Unknown") %>% # delete unknown races
  mutate(city_state = paste(city, state, sep = ", "), 
         solved = ifelse(disposition == "Closed by arrest", 1, 0), # a binary indicator
         victim_race = ifelse(victim_race == "White", "White", "Nonwhite"), 
         victim_race = factor(victim_race, levels = c("White", "Nonwhite")), # a white / non white indicator
         victim_age = as.numeric(victim_age)) %>% 
  filter(!(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"))) # filter cities
```

### a logistic regression

```{r}
# first fit it
fit_logistic =
  homi_df %>% 
  glm(solved ~ victim_age + victim_sex + victim_race, data = ., family = binomial())

# then compute the odds ratio
fit_logistic %>% 
  broom::tidy(conf.int = T) %>% 
  mutate(OR = exp(estimate), 
         conf.low = exp(conf.low), 
         conf.high = exp(conf.high)) %>% 
  select(term, OR, conf.low, conf.high, p.value) %>% 
  filter(term %in% c("(Intercept)", "victim_raceNonwhite")) %>% 
  knitr::kable()
```

### run `glm` for each of the cities

```{r}
nest_glm_res = 
  homi_df %>% 
  group_by(city_state) %>% 
  nest() %>% 
  mutate(models = map(data, ~glm(solved ~ victim_race + victim_age + victim_sex, data = .x, family = binomial())), 
         models_esti = map(models, broom::tidy), # tidying for estimate
         models_conf = map(models, broom::confint_tidy)) %>% # tyding for conf.int
  select(-data, -models) %>%
  unnest() %>% 
  filter(term %in% c("(Intercept)", "victim_raceNonwhite")) %>% 
  mutate(OR = exp(estimate), 
         conf.low = exp(conf.low), 
         conf.high = exp(conf.high)) %>% 
  select(city_state, term, OR, conf.low, conf.high, p.value)

nest_glm_res
```

Then create a plot that shows the estimated ORs and CIs for each city, and comment on the plot.

```{r, dpi = 300}
nest_glm_res %>% 
  filter(term == "victim_raceNonwhite") %>% 
  ggplot(aes(x = reorder(city_state, OR), y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  labs(x = "city", 
       y = "ORs and CIs for nonwhite victims comparing to white victims") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

According to this plot, we can see that across every cities, non white victims tend to have more unsolved homicides comparing to white victims (with `Boston, MA` has the least extra unsolved and `Tampa, FL` has the most extra unsolved).

## Problem 2

### Load and clean the data

```{r}
bw_df = 
  read.csv("./data/problem2/birthweight.csv") %>% 
  as.tibble() %>% 
  janitor::clean_names() %>% 
  select(bwt, everything())
```

* We first checked if there is `NA` in this dataset, and found out that there are `r sum(is.na(bw_df))` `NA`s.

* Second we check the collinearity:

```{r}
bw_df %>% 
  cor() %>% 
  knitr::kable()
```

We saw that the standard deviation for `pnumlbw` and `pnumsga` is 0, so we looked these two variables and found out that their sum is `r sum(bw_df$pnumlbw)` and `r sum(bw_df$pnumsga)`, which suggest that all the values in these two columns are 0s, so we need to remove these two columns.

We also saw that cor(`ppwt`, `delwt`), cor(`ppwt`, `ppbmi`) , cor(`ppbmi`, `delwt`), and cor(`frace`, `mrace`) are $\geq 0.8$. In these case, we remove the `ppwt`, `delwt` and `frace` columns since mother race is more related to child and weight gain and BMI are more representative than absolute body weight. Then we change some variable to factors:

```{r}
bw_df =
  bw_df %>% 
  select(-pnumlbw, -pnumsga, -ppwt, -frace, -delwt) %>% 
  mutate(babysex = factor(babysex),
         malform = factor(malform),
         mrace = factor(mrace, levels = c(1, 2, 3, 4, 8)))
```

### Propose a regression model for birthweight

We used AIC criterion stepwise method to find the optimal parameters:

```{r}
lm(bwt ~ ., data = bw_df) %>% 
  step(direction='backward')
```

So based on the result, the final paremeters we chose are: `babysex + bhead + blength + fincome + gaweeks + mheight + mrace + parity + ppbmi + smoken + wtgain`

```{r, dpi = 300}
reg_optimal = lm(bwt ~ babysex + bhead + blength + fincome + gaweeks + mheight + mrace + parity + ppbmi + smoken + wtgain, data = bw_df)

bw_df %>% 
  modelr::add_predictions(reg_optimal) %>% 
  modelr::add_residuals(reg_optimal) %>% 
  ggplot(aes(x = pred, y = resid)) + geom_point()
```

### Compare your model to two others

```{r, dpi = 300}
cv_df = 
  modelr::crossv_mc(bw_df, 1000) %>% 
  mutate(train = map(train, as.tibble), 
         test = map(test, as.tibble)) %>% 
  mutate(optimal_mod = map(train, ~lm(bwt ~ babysex + bhead + blength + fincome + gaweeks + mheight + mrace + parity + ppbmi + smoken + wtgain, data = .x)), 
         test1_mod = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)), 
         test2_mod = map(train, ~lm(bwt ~ bhead * blength * babysex, data = .x))) %>% 
  mutate(rmse_optimal = map2_dbl(optimal_mod, test, ~modelr::rmse(model = .x, data = .y)), 
         rmse_test1 = map2_dbl(test1_mod, test, ~modelr::rmse(model = .x, data = .y)),
         rmse_test2 = map2_dbl(test2_mod, test, ~modelr::rmse(model = .x, data = .y)))

cv_df %>% 
  select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

Based on these plot, we saw thereâ€™s clearly some improvement in predictive accuracy gained by our optimal model.